# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DRtkEeZFajBpj4bSyTcMAOlwHwFwzNLa
"""

import google.generativeai as genai
import json
import os
from flask import Flask, request, jsonify, render_template

# Configurar Gemini AI
genai.configure(api_key="TU_GEMINI_API_KEY")

#  **Definir archivo de memoria**
MEMORY_FILE = "chatbot_memory.json"

#  **Funci贸n para cargar memoria desde el archivo**
def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)  # Cargar memoria desde JSON
    return {}  # Si no existe, devuelve un diccionario vac铆o

#  **Funci贸n para guardar la memoria en el archivo**
def save_memory():
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(knowledge_base, f, indent=4, ensure_ascii=False)

#  **Cargar memoria en el diccionario**
knowledge_base = load_memory()

#  **Prompts Inteligentes para Optimizar la Respuesta**
base_prompt = """
Eres un asistente tur铆stico especializado en Puerto Rico. Tu objetivo es proporcionar informaci贸n detallada y precisa sobre lugares tur铆sticos, historia, clima, eventos y gastronom铆a de Puerto Rico.
Siempre analiza la pregunta antes de responder y razona sobre la mejor manera de contestarla.

 **Reglas de respuesta:**
1锔 **Si el usuario menciona "Top X lugares", genera exactamente X lugares en base a rese帽as y popularidad.**
2锔 **Si el usuario pregunta por el clima, consulta OpenWeather y responde con informaci贸n actualizada.**
3锔 **Si la pregunta es general, responde con informaci贸n tur铆stica relevante sin restricciones.**
4锔 **Nunca respondas con informaci贸n que no sea de Puerto Rico.**
"""

geography_prompt = "Estudia los 78 municipios de Puerto Rico y sus atractivos tur铆sticos."
history_prompt = "Aprende sobre la historia de Puerto Rico y sus eventos culturales m谩s importantes."
food_prompt = "Investiga la gastronom铆a de Puerto Rico, platos t铆picos y mejores restaurantes."
top_places_prompt = "Si el usuario pide un 'Top X lugares', genera X lugares seg煤n popularidad."
climate_prompt = "Si el usuario pregunta por el clima, consulta OpenWeather y proporciona la informaci贸n actualizada."

#  **Funci贸n para generar respuestas con Gemini AI**
def chatbot_response(user_input):
    try:
        #  **Verificar si ya tenemos la respuesta guardada**
        if user_input in knowledge_base:
            return knowledge_base[user_input]  # Retorna la respuesta guardada

        #  **Concatenamos los prompts para que Gemini piense mejor**
        model = genai.GenerativeModel("gemini-pro")
        prompt = f"""
        {base_prompt}
        {geography_prompt}
        {history_prompt}
        {food_prompt}
        {top_places_prompt}
        {climate_prompt}

         **Pregunta del usuario:** {user_input}
        """

        # Generar respuesta con Gemini
        response = model.generate_content(prompt)
        final_response = response.text.strip()

        #  **Guardar en memoria para futuras respuestas**
        knowledge_base[user_input] = final_response
        save_memory()  # Guardar en archivo JSON

        return final_response

    except Exception as e:
        return f"锔 Error con Gemini: {str(e)}"

#  **Configurar Flask**
app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    data = request.get_json()
    user_query = data.get("message", "")
    response = chatbot_response(user_query)
    return jsonify({"response": response})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)