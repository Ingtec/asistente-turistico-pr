# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DRtkEeZFajBpj4bSyTcMAOlwHwFwzNLa
"""

import google.generativeai as genai
import json
import os
from flask import Flask, request, jsonify, render_template

# Configurar Gemini AI
genai.configure(api_key="TU_GEMINI_API_KEY")

# 📌 **Definir archivo de memoria**
MEMORY_FILE = "chatbot_memory.json"

# 🔹 **Función para cargar memoria desde el archivo**
def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)  # Cargar memoria desde JSON
    return {}  # Si no existe, devuelve un diccionario vacío

# 🔹 **Función para guardar la memoria en el archivo**
def save_memory():
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(knowledge_base, f, indent=4, ensure_ascii=False)

# 🔹 **Cargar memoria en el diccionario**
knowledge_base = load_memory()

# 🧠 **Prompts Inteligentes para Optimizar la Respuesta**
base_prompt = """
Eres un asistente turístico especializado en Puerto Rico. Tu objetivo es proporcionar información detallada y precisa sobre lugares turísticos, historia, clima, eventos y gastronomía de Puerto Rico.
Siempre analiza la pregunta antes de responder y razona sobre la mejor manera de contestarla.

📌 **Reglas de respuesta:**
1️⃣ **Si el usuario menciona "Top X lugares", genera exactamente X lugares en base a reseñas y popularidad.**
2️⃣ **Si el usuario pregunta por el clima, consulta OpenWeather y responde con información actualizada.**
3️⃣ **Si la pregunta es general, responde con información turística relevante sin restricciones.**
4️⃣ **Nunca respondas con información que no sea de Puerto Rico.**
"""

geography_prompt = "Estudia los 78 municipios de Puerto Rico y sus atractivos turísticos."
history_prompt = "Aprende sobre la historia de Puerto Rico y sus eventos culturales más importantes."
food_prompt = "Investiga la gastronomía de Puerto Rico, platos típicos y mejores restaurantes."
top_places_prompt = "Si el usuario pide un 'Top X lugares', genera X lugares según popularidad."
climate_prompt = "Si el usuario pregunta por el clima, consulta OpenWeather y proporciona la información actualizada."

# 🤖 **Función para generar respuestas con Gemini AI**
def chatbot_response(user_input):
    try:
        # 📌 **Verificar si ya tenemos la respuesta guardada**
        if user_input in knowledge_base:
            return knowledge_base[user_input]  # Retorna la respuesta guardada

        # 🔥 **Concatenamos los prompts para que Gemini piense mejor**
        model = genai.GenerativeModel("gemini-pro")
        prompt = f"""
        {base_prompt}
        {geography_prompt}
        {history_prompt}
        {food_prompt}
        {top_places_prompt}
        {climate_prompt}

        📌 **Pregunta del usuario:** {user_input}
        """

        # Generar respuesta con Gemini
        response = model.generate_content(prompt)
        final_response = response.text.strip()

        # 🔹 **Guardar en memoria para futuras respuestas**
        knowledge_base[user_input] = final_response
        save_memory()  # Guardar en archivo JSON

        return final_response

    except Exception as e:
        return f"⚠️ Error con Gemini: {str(e)}"

# 🚀 **Configurar Flask**
app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    data = request.get_json()
    user_query = data.get("message", "")
    response = chatbot_response(user_query)
    return jsonify({"response": response})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)